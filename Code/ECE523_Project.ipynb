{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8fed4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, TFBertModel, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, TFAutoModel\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839c7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def organizeData(self, featuresFile, patientNotesFile, trainFile):\n",
    "        self.fDF = pd.read_csv(featuresFile)\n",
    "        self.pnDF = pd.read_csv(patientNotesFile)\n",
    "        self.tDF = pd.read_csv(trainFile)\n",
    "\n",
    "        self.tDF['annotation_list'] = self.tDF['annotation'].apply(literal_eval)\n",
    "        self.tDF['location_list'] = self.tDF['location'].apply(literal_eval)\n",
    "\n",
    "        self.removeORs()\n",
    "        self.removeSpecialChars()\n",
    "        \n",
    "        self.merged = self.tDF.merge(self.pnDF, how=\"left\")\n",
    "        self.merged = self.merged.merge(self.fDF, how=\"left\")\n",
    "        #self.merged['annotation_length'] = self.tDF['annotation'].apply(len)\n",
    "\n",
    "    def removeORs(self):\n",
    "        self.fDF['feature_text'] = self.fDF['feature_text'].apply(lambda x: x.lower())\n",
    "        for i in range(len(self.fDF['feature_text'])):\n",
    "            self.fDF.at[i, 'feature_text'] = self.fDF['feature_text'][i].replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n",
    "\n",
    "    def removeSpecialChars(self):\n",
    "        self.pnDF['pn_history'] = self.pnDF['pn_history'].apply(lambda x: x.lower())\n",
    "        for i in range(len(self.pnDF['pn_history'])):\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"(\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\")\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\":\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\";\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"-\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"/\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"\\\\\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"\\r\\n\", \"  \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"\\'\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\"\\\"\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\",\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = self.pnDF['pn_history'][i].replace(\".\", \" \")\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bzero\\b', ' 0  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bone\\b', ' 1 ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\btwo\\b', ' 2 ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bthree\\b', '  3  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bfour\\b', ' 4  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bfive\\b', ' 5  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bsix\\b', ' 6 ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bseven\\b', '  7  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\beight\\b', '  8  ', self.pnDF['pn_history'][i])\n",
    "            self.pnDF.at[i, 'pn_history'] = re.sub(r'\\bnine\\b', ' 9  ', self.pnDF['pn_history'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ff06f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family history of mi or family history of myocardial infarction\n",
      "17 year old male  has come to the student health clinic complaining of heart pounding  mr  cleveland s mother has given verbal consent for a history  physical examination  and treatment   began 2 3 months ago sudden intermittent for 2 days lasting 3 4 min  worsening non allev aggrav   associated with dispnea on exersion and rest stressed out about school   reports fe feels like his heart is jumping out of his chest   ros denies chest pain dyaphoresis wt loss chills fever nausea vomiting pedal edeam   pmh non meds  aderol  from a friend  nkda   fh father had mi recently mother has thyroid dz   sh non smoker mariguana 5 6 months ago 3 beers on the weekend  basketball at school   sh no std\n"
     ]
    }
   ],
   "source": [
    "featuresFile = \"..\\\\CSVs\\\\features.csv\"\n",
    "patientNotesFile = \"..\\\\CSVs\\\\patient_notes.csv\"\n",
    "trainFile = \"..\\\\CSVs\\\\train.csv\"\n",
    "\n",
    "prep = Preprocessing()\n",
    "prep.organizeData(featuresFile, patientNotesFile, trainFile)\n",
    "\n",
    "print(prep.fDF['feature_text'][0])\n",
    "print(prep.pnDF['pn_history'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e28755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>annotation_list</th>\n",
       "      <th>location_list</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>hpi  17yo m presents with palpitations  patien...</td>\n",
       "      <td>family history of mi or family history of myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>['mom with \"thyroid disease']</td>\n",
       "      <td>['668 693']</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>hpi  17yo m presents with palpitations  patien...</td>\n",
       "      <td>family history of thyroid disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>['chest pressure']</td>\n",
       "      <td>['203 217']</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>hpi  17yo m presents with palpitations  patien...</td>\n",
       "      <td>chest pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>['intermittent episodes', 'episode']</td>\n",
       "      <td>['70 91', '176 183']</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>hpi  17yo m presents with palpitations  patien...</td>\n",
       "      <td>intermittent symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>['felt as if he were going to pass out']</td>\n",
       "      <td>['222 258']</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>hpi  17yo m presents with palpitations  patien...</td>\n",
       "      <td>lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                 annotation              location  \\\n",
       "0          ['dad with recent heart attcak']           ['696 724']   \n",
       "1             ['mom with \"thyroid disease']           ['668 693']   \n",
       "2                        ['chest pressure']           ['203 217']   \n",
       "3      ['intermittent episodes', 'episode']  ['70 91', '176 183']   \n",
       "4  ['felt as if he were going to pass out']           ['222 258']   \n",
       "\n",
       "                          annotation_list     location_list  \\\n",
       "0          [dad with recent heart attcak]         [696 724]   \n",
       "1             [mom with \"thyroid disease]         [668 693]   \n",
       "2                        [chest pressure]         [203 217]   \n",
       "3        [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4  [felt as if he were going to pass out]         [222 258]   \n",
       "\n",
       "                                          pn_history  \\\n",
       "0  hpi  17yo m presents with palpitations  patien...   \n",
       "1  hpi  17yo m presents with palpitations  patien...   \n",
       "2  hpi  17yo m presents with palpitations  patien...   \n",
       "3  hpi  17yo m presents with palpitations  patien...   \n",
       "4  hpi  17yo m presents with palpitations  patien...   \n",
       "\n",
       "                                        feature_text  \n",
       "0  family history of mi or family history of myoc...  \n",
       "1                 family history of thyroid disorder  \n",
       "2                                     chest pressure  \n",
       "3                              intermittent symptoms  \n",
       "4                                        lightheaded  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2eb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens 162\n",
      "['family', 'history', 'of', 'mi', 'or', 'family', 'history', 'of', 'my', '##oca', '##rdial', 'in', '##far', '##ction', '17', 'year', 'old', 'male', 'has', 'come', 'to', 'the', 'student', 'health', 'clinic', 'complaining', 'of', 'heart', 'pounding', 'mr', 'cleveland', 's', 'mother', 'has', 'given', 'verbal', 'consent', 'for', 'a', 'history', 'physical', 'examination', 'and', 'treatment', 'began', '2', '3', 'months', 'ago', 'sudden', 'intermittent', 'for', '2', 'days', 'lasting', '3', '4', 'min', 'worse', '##ning', 'non', 'all', '##ev', 'ag', '##gra', '##v', 'associated', 'with', 'di', '##sp', '##nea', 'on', 'ex', '##ers', '##ion', 'and', 'rest', 'stressed', 'out', 'about', 'school', 'reports', 'fe', 'feels', 'like', 'his', 'heart', 'is', 'jumping', 'out', 'of', 'his', 'chest', 'ro', '##s', 'denies', 'chest', 'pain', 'd', '##ya', '##ph', '##ores', '##is', 'w', '##t', 'loss', 'chill', '##s', 'fever', 'nausea', 'vomiting', 'pedal', 'ed', '##ea', '##m', 'pm', '##h', 'non', 'med', '##s', 'ad', '##ero', '##l', 'from', 'a', 'friend', 'nk', '##da', 'f', '##h', 'father', 'had', 'mi', 'recently', 'mother', 'has', 'thyroid', 'd', '##z', 'sh', 'non', 'smoke', '##r', 'mari', '##gua', '##na', '5', '6', 'months', 'ago', '3', 'beers', 'on', 'the', 'weekend', 'basketball', 'at', 'school', 'sh', 'no', 'st', '##d']\n",
      "{'input_ids': [101, 2459, 2095, 2214, 3287, 2038, 2272, 2000, 1996, 3076, 2740, 9349, 17949, 1997, 2540, 9836, 2720, 6044, 1055, 2388, 2038, 2445, 12064, 9619, 2005, 1037, 2381, 3558, 7749, 1998, 3949, 2211, 1016, 1017, 2706, 3283, 5573, 23852, 2005, 1016, 2420, 9879, 1017, 1018, 8117, 4788, 5582, 2512, 2035, 6777, 12943, 17643, 2615, 3378, 2007, 4487, 13102, 22084, 2006, 4654, 2545, 3258, 1998, 2717, 13233, 2041, 2055, 2082, 4311, 10768, 5683, 2066, 2010, 2540, 2003, 8660, 2041, 1997, 2010, 3108, 20996, 2015, 23439, 3108, 3255, 1040, 3148, 8458, 16610, 2483, 1059, 2102, 3279, 10720, 2015, 9016, 19029, 24780, 15749, 3968, 5243, 2213, 7610, 2232, 2512, 19960, 2015, 4748, 10624, 2140, 2013, 1037, 2767, 25930, 2850, 1042, 2232, 2269, 2018, 2771, 3728, 2388, 2038, 29610, 1040, 2480, 14021, 2512, 5610, 2099, 16266, 19696, 2532, 1019, 1020, 2706, 3283, 1017, 18007, 2006, 1996, 5353, 3455, 2012, 2082, 14021, 2053, 2358, 2094, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "tokens = tokenizer.tokenize(prep.fDF['feature_text'][0], prep.pnDF['pn_history'][0])\n",
    "\n",
    "print(\"Total Tokens\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer(prep.pnDF['pn_history'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3395b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mom with  thyroid disease\n",
      "Seq ID zero, so level is -1 also\n",
      "Word mom, label: 1\n",
      "Word with, label: 1\n",
      "Word thyroid, label: 1\n",
      "Word disease, label: 1\n"
     ]
    }
   ],
   "source": [
    "tokenized_list = tokenizer(\n",
    "        prep.merged.iloc[0].feature_text,\n",
    "        prep.merged.iloc[0].pn_history,\n",
    "        truncation=True,\n",
    "        max_length=1000,\n",
    "        padding='max_length',\n",
    "        return_offsets_mapping=True\n",
    ")\n",
    "print(prep.merged.iloc[0].pn_history[668:693])\n",
    "\n",
    "zipped = zip(tokenized_list.sequence_ids(), tokenized_list[\"offset_mapping\"])\n",
    "\n",
    "idx, (seq_id, offsets) = next(enumerate(zipped))\n",
    "if not seq_id or seq_id == 0:\n",
    "    print(\"Seq ID zero, so level is -1 also\")\n",
    "\n",
    "seq_id = 1 #assume\n",
    "loc_list = [668, 693]\n",
    "\n",
    "for idx, (seq_id, offsets)  in enumerate(zip(tokenized_list.sequence_ids(), tokenized_list[\"offset_mapping\"])):\n",
    "    token_start, token_end = offsets\n",
    "    for feature_start, feature_end in [loc_list]:\n",
    "        if token_start >= feature_start and token_end <= feature_end:\n",
    "            print(f\"Word {prep.merged.iloc[0].pn_history[token_start:token_end]}, label: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e9c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,normalization=True)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c26ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMPTY', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 700, 701, 702, 703, 704, 705, 706, 707, 708, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916]\n",
      "['0' '1' '2' ... '914' '915' '916']\n",
      "0          0\n",
      "1          1\n",
      "2         18\n",
      "3         36\n",
      "4         53\n",
      "        ... \n",
      "14295    138\n",
      "14296    139\n",
      "14297    140\n",
      "14298    141\n",
      "14299    142\n",
      "Name: TARGET, Length: 14300, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "EMPTY =  'EMPTY'\n",
    "CLASSES = [EMPTY,]+prep.fDF.feature_num.unique().tolist()\n",
    "print(CLASSES)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(CLASSES)\n",
    "features = np.asarray(prep.merged['feature_num'], dtype = str)\n",
    "print(features)\n",
    "prep.merged['TARGET'] = label_encoder.transform(features)\n",
    "N_CLASSES = len(label_encoder.classes_)\n",
    "EMPTY_IDX = label_encoder.transform([EMPTY,]) [0]\n",
    "print(prep.merged['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babacb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_location(locations):\n",
    "    for x in [\"[\",\"]\",\"'\"]:\n",
    "        locations = locations.replace(x,'')\n",
    "    locations = locations.replace(',',';')\n",
    "    locations = locations.split(\";\")\n",
    "    res = []\n",
    "    for location in locations:\n",
    "        if location:\n",
    "            x,y = location.split()\n",
    "            res.append((int(x),int(y)))\n",
    "    return sorted(res,key=lambda x:x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e479f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51ca734015e445d816808c6b4c7195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences, labels, masks = [], [], []\n",
    "for g1 in tqdm(prep.merged.groupby('pn_num')):\n",
    "    gdf = g1[1]\n",
    "    pn_history  = gdf.iloc[0].pn_history\n",
    "\n",
    "    tokens = tokenizer.encode_plus(pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n",
    "    sequence = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    label = np.array([EMPTY_IDX for _ in range(SEQUENCE_LENGTH)])\n",
    "\n",
    "    # BUILD THE TARGET ARRAY\n",
    "    offsets = tokens['offset_mapping']\n",
    "    label_empty = True\n",
    "    for index, row in gdf.iterrows():\n",
    "        TARGET = row.TARGET\n",
    "        for i, (w_start, w_end) in enumerate(offsets):\n",
    "            for start,end in decode_location(row.location):\n",
    "                if w_start < w_end and (w_start >= start) and (end >= w_end):\n",
    "                    label[i] = TARGET\n",
    "                    label_empty = False\n",
    "                if w_start >= w_end:\n",
    "                    break\n",
    "    if not label_empty:\n",
    "        sequences.append(sequence)\n",
    "        masks.append(attention_mask)\n",
    "        labels.append(label)\n",
    "\n",
    "sequences = np.array(sequences).astype(np.int32)\n",
    "masks = np.array(masks).astype(np.uint8)\n",
    "labels = np.array(tf.keras.utils.to_categorical(labels,N_CLASSES)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c55b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    tokens = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'tokens', dtype=tf.int32)\n",
    "    attention = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'attention', dtype=tf.int32)\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    backbone = TFAutoModel.from_pretrained(MODEL_NAME,config=config)\n",
    "    \n",
    "    out = backbone(tokens, attention_mask=attention)[0]\n",
    "    out = tf.keras.layers.Dropout(0.2)(out)\n",
    "    out = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(out)\n",
    "    \n",
    "    model = tf.keras.Model([tokens,attention],out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582975de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      " 1/84 [..............................] - ETA: 1:50:39 - loss: 5.4660 - acc: 3.2552e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20288\\3188499648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                         callbacks=[callback,])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2957\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1854\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = build_model()\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=3)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                  loss=tf.keras.losses.categorical_crossentropy,metrics=['acc',])\n",
    "\n",
    "    history = model.fit((sequences,masks),labels,\n",
    "                        batch_size=12,\n",
    "                        epochs=1,\n",
    "                        callbacks=[callback,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1d367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
